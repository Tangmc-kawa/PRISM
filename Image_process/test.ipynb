{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mingchuan\\anaconda3\\envs\\cell-typing\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\Mingchuan\\anaconda3\\envs\\cell-typing\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\Mingchuan\\anaconda3\\envs\\cell-typing\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "from skimage.io import imread\n",
    "from scipy.spatial import KDTree\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "\n",
    "CHANNELS = ['cy5', 'TxRed', 'cy3', 'FAM']\n",
    "BASE_DIR = Path('E:/TMC/PRISM_pipeline/dataset/processed')\n",
    "RUN_ID = '_example_dataset'\n",
    "src_dir = BASE_DIR / f'{RUN_ID}_processed'\n",
    "stc_dir = src_dir / 'stitched'\n",
    "read_dir = src_dir / 'readout'\n",
    "os.makedirs(read_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "TOPHAT_KERNEL_SIZE = 7\n",
    "def tophat_spots(image):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(TOPHAT_KERNEL_SIZE,TOPHAT_KERNEL_SIZE))\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "\n",
    "def divide_main(func, shape, max_volume=10**9, overlap=500):\n",
    "    zrange, xrange, yragne = shape\n",
    "    xy_size =  int(np.sqrt(max_volume / zrange))\n",
    "    x_num = -(-(xrange - overlap) // (xy_size - overlap))\n",
    "    y_num = -(-(yragne - overlap) // (xy_size - overlap))\n",
    "    cut_x = xrange // x_num + overlap\n",
    "    cut_y = yragne // y_num + overlap\n",
    "    print(f\"n_tile: {x_num * y_num};\", f\"\\nx_slice_num: {x_num};\", f\"y_slice_num: {y_num};\")\n",
    "    print(f\"block_x: {cut_x};\", f\"block_y: {cut_y};\", f\"overlap: {overlap};\")\n",
    "    \n",
    "    pad_x, pad_y = 1, 1\n",
    "    x_step = cut_x - overlap\n",
    "    y_step = cut_y - overlap\n",
    "    with tqdm(total=x_num * y_num, desc='tile') as pbar:\n",
    "        for x_pos in range(x_num):\n",
    "            for y_pos in range(y_num):\n",
    "                func(pad_x, cut_x, pad_y, cut_y, x_pos, y_pos, x_num, y_num, overlap)\n",
    "                pad_y += y_step\n",
    "                pbar.update(1)\n",
    "            pad_x += x_step\n",
    "            pad_y = 0\n",
    "\n",
    "\n",
    "def extract_coordinates(image, snr=4, quantile=0.96):\n",
    "    meta = {}\n",
    "    coordinates = peak_local_max(image,min_distance=2,threshold_abs=snr*np.mean(image))\n",
    "    meta['Coordinates brighter than given SNR'] = coordinates.shape[0]\n",
    "    meta['Image mean intensity'] = float(np.mean(image))\n",
    "    intensities = image[coordinates[:,0],coordinates[:,1]]\n",
    "    meta[f'{quantile} quantile'] = float(np.quantile(intensities,quantile))\n",
    "    threshold = np.quantile(intensities,quantile)\n",
    "    coordinates = coordinates[image[coordinates[:,0],coordinates[:,1]]>threshold]\n",
    "    meta['Final spots count'] = coordinates.shape[0]\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def extract_signal(image, pad_x, cut_x, pad_y, cut_y, pad_width = [(1, 0), (1, 0)], \n",
    "                 QUANTILE = 0.1, kernel = np.ones((5,5), np.uint8)):\n",
    "    # add pad and get a subset of image\n",
    "    image = np.pad(image, pad_width, constant_values=0)\n",
    "    image = image[pad_y : pad_y + cut_y, pad_x : pad_x + cut_x]\n",
    "    image = tophat_spots(image)\n",
    "    image[image < 100] = 0\n",
    "\n",
    "    # extract coordinates\n",
    "    coordinates = extract_coordinates(image, 8, quantile=QUANTILE) \n",
    "    \n",
    "    # find signal\n",
    "    Maxima = np.zeros(image.shape, dtype=np.uint16)\n",
    "    Maxima[coordinates[:,0],coordinates[:,1]] = 255\n",
    "    image[Maxima<=0] = 0 # Mask\n",
    "\n",
    "    # dilation of image\n",
    "    image = cv2.dilate(image, kernel,iterations=1)\n",
    "    return coordinates, image\n",
    "\n",
    "\n",
    "def read_intensity(image_dict, coordinates):\n",
    "    intensity = pd.DataFrame({'Y': coordinates[:, 0], 'X': coordinates[:, 1]})\n",
    "    for image_name, image in image_dict.items():\n",
    "         intensity[image_name] = image[coordinates[:, 0], coordinates[:, 1]]\n",
    "    return intensity\n",
    "\n",
    "\n",
    "def remove_duplicates(coordinates):\n",
    "    tree = KDTree(coordinates)\n",
    "    pairs = tree.query_pairs(2)\n",
    "    #print(f'{len(pairs)} duplicates pairs')\n",
    "    neighbors = {} #dictionary of neighbors\n",
    "    for i,j in pairs: #iterate over all pairs\n",
    "        if i not in neighbors:\n",
    "            neighbors[i] = set([j])\n",
    "        else:\n",
    "            neighbors[i].add(j)\n",
    "        if j not in neighbors:\n",
    "            neighbors[j] = set([i])\n",
    "        else:\n",
    "            neighbors[j].add(i)\n",
    "    #print(f'{len(neighbors)} neighbor entries')\n",
    "    keep = []\n",
    "    discard = set() # a list would work, but I use a set for fast member testing with `in`\n",
    "    nodes = set([s[0] for s in pairs]+[s[1] for s in pairs])\n",
    "    for node in nodes:\n",
    "        if node not in discard: # if node already in discard set: skip\n",
    "            keep.append(node) # add node to keep list\n",
    "            discard.update(neighbors.get(node,set())) #add node's neighbors to discard set\n",
    "    #print(f'{len(discard)} nodes discarded, {len(keep)} nodes kept')\n",
    "    centroids_simplified = np.delete(coordinates, list(discard), axis=0)\n",
    "    #print(f'{centroids_simplified.shape[0]} centroids after simplification')\n",
    "    return centroids_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity = pd.read_csv(read_dir/'intensity_all.csv', index_col=0)\n",
    "\n",
    "# deduplicate\n",
    "intensity['ID'] = intensity['Y'] * 10**7 + intensity['X']\n",
    "intensity = intensity.drop_duplicates(subset=['Y','X'])\n",
    "\n",
    "df = intensity[['Y', 'X', 'R', 'Ye', 'B', 'G']]\n",
    "df_reduced = pd.DataFrame()\n",
    "coordinates = df[['Y','X']].values\n",
    "coordinates = remove_duplicates(coordinates)\n",
    "df_reduced = pd.DataFrame(coordinates, columns=['Y','X'])\n",
    "\n",
    "df_reduced['ID'] = df_reduced['Y'] * 10**7 + df_reduced['X']\n",
    "intensity = intensity[intensity['ID'].isin(df_reduced['ID'])]\n",
    "\n",
    "intensity = intensity.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# crosstalk elimination\n",
    "intensity['B'] = intensity['B'] - intensity['G'] * 0.25 \n",
    "intensity = np.maximum(intensity, 0)\n",
    "\n",
    "# Scale\n",
    "intensity['Scaled_R'] = intensity['R']\n",
    "intensity['Scaled_Ye'] = intensity['Ye']\n",
    "intensity['Scaled_G'] = intensity['G'] * 2.5\n",
    "intensity['Scaled_B'] = intensity['B']\n",
    "\n",
    "# normalize\n",
    "intensity['sum'] = intensity['Scaled_R'] + intensity['Scaled_Ye'] + intensity['Scaled_B']\n",
    "intensity['R/A'] = intensity['Scaled_R'] / intensity['sum']\n",
    "intensity['Ye/A'] = intensity['Scaled_Ye'] / intensity['sum']\n",
    "intensity['B/A'] = intensity['Scaled_B'] / intensity['sum']\n",
    "intensity['G/A'] = intensity['Scaled_G'] / intensity['sum']\n",
    "intensity = intensity.dropna()\n",
    "\n",
    "intensity['G/A'][intensity['G/A'] > 5] = 5\n",
    "intensity['G/A'] = intensity['G/A'] * np.exp(0.8 * intensity['Ye/A'])\n",
    "\n",
    "# transform\n",
    "RYB_x_transform = np.array([[-np.sqrt(2)/2], [0], [np.sqrt(2)/2]])\n",
    "RYB_y_transform = np.array([[-np.sqrt(3)/3], [2/np.sqrt(3)], [-np.sqrt(3)/3]])\n",
    "intensity['X_coor'] = intensity[['Ye/A', 'B/A', 'R/A',]] @ RYB_x_transform\n",
    "intensity['Y_coor'] = intensity[['Ye/A', 'B/A', 'R/A',]] @ RYB_y_transform\n",
    "\n",
    "intensity.to_csv(read_dir/'intensity_deduplicated.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell-typing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
